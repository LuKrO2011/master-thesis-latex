%%%%%%%%%%%%%%%%%
% From Template %
%%%%%%%%%%%%%%%%%

\documentclass[%
class=scrreprt,
chapterprefix=false,%
open=right,%
twoside=false,%
paper=a4,%
logofile={Logo\_zentral\_farbig\_EN.png},%
thesistype=masterproposal,%
UKenglish,%
]{se2thesis}
\listfiles
\usepackage[ngerman,main=UKenglish]{babel}
\usepackage{blindtext}
\usepackage[%
csquotes=true,%
booktabs=true,%
siunitx=true,%
minted=true,%
selnolig=true,%
widowcontrol=false,%
microtype=true,%
biblatex=true,%
cleveref=true,%
]{se2packages}

\begin{filecontents}{\jobname.bib}
	@article{boehm2001defect,
		title={Defect reduction top 10 list},
		author={Boehm, Barry and Basili, Victor R},
		journal={Computer},
		volume={34},
		number={1},
		pages={135--137},
		year={2001}
	}
	
	@article{buse2009learning,
		title={Learning a metric for code readability},
		author={Buse, Raymond PL and Weimer, Westley R},
		journal={IEEE Transactions on software engineering},
		volume={36},
		number={4},
		pages={546--558},
		year={2009},
		publisher={IEEE}
	}
	
	@inproceedings{aggarwal2002integrated,
		title={An integrated measure of software maintainability},
		author={Aggarwal, Krishan K and Singh, Yogesh and Chhabra, Jitender Kumar},
		booktitle={Annual Reliability and Maintainability Symposium. 2002 Proceedings (Cat. No. 02CH37318)},
		pages={235--241},
		year={2002},
		organization={IEEE}
	}
	
	@inproceedings{fakhoury2019improving,
		title={Improving source code readability: Theory and practice},
		author={Fakhoury, Sarah and Roy, Devjeet and Hassan, Adnan and Arnaoudova, Vernera},
		booktitle={2019 IEEE/ACM 27th International Conference on Program Comprehension (ICPC)},
		pages={2--12},
		year={2019},
		organization={IEEE}
	}
	
	@inproceedings{scalabrino2016improving,
		title={Improving code readability models with textual features},
		author={Scalabrino, Simone and Linares-Vasquez, Mario and Poshyvanyk, Denys and Oliveto, Rocco},
		booktitle={2016 IEEE 24th International Conference on Program Comprehension (ICPC)},
		pages={1--10},
		year={2016},
		organization={IEEE}
	}
	
	@inproceedings{posnett2011simpler,
		title={A simpler model of software readability},
		author={Posnett, Daryl and Hindle, Abram and Devanbu, Premkumar},
		booktitle={Proceedings of the 8th working conference on mining software repositories},
		pages={73--82},
		year={2011}
	}
	
	@article{dorn2012general,
		title={A general software readability model},
		author={Dorn, Jonathan},
		journal={MCS Thesis available from (http://www. cs. virginia. edu/weimer/students/dorn-mcs-paper. pdf)},
		volume={5},
		pages={11--14},
		year={2012}
	}
	
	@inproceedings{scalabrino2017automatically,
		title={Automatically assessing code understandability: How far are we?},
		author={Scalabrino, Simone and Bavota, Gabriele and Vendome, Christopher and Linares-V{\'a}squez, Mario and Poshyvanyk, Denys and Oliveto, Rocco},
		booktitle={2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)},
		pages={417--427},
		year={2017},
		organization={IEEE}
	}
	
	@inproceedings{daka2015modeling,
		title={Modeling readability to improve unit tests},
		author={Daka, Ermira and Campos, Jos{\'e} and Fraser, Gordon and Dorn, Jonathan and Weimer, Westley},
		booktitle={Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
		pages={107--118},
		year={2015}
	}
	
	@article{mi2022towards,
		title={Towards using visual, semantic and structural features to improve code readability classification},
		author={Mi, Qing and Hao, Yiqun and Ou, Liwei and Ma, Wei},
		journal={Journal of Systems and Software},
		volume={193},
		pages={111454},
		year={2022},
		publisher={Elsevier}
	}
	
	@inproceedings{mi2018gamification,
		title={A gamification technique for motivating students to learn code readability in software engineering},
		author={Mi, Qing and Keung, Jacky and Mei, Xiupei and Xiao, Yan and Chan, WK},
		booktitle={2018 International Symposium on Educational Technology (ISET)},
		pages={250--254},
		year={2018},
		organization={IEEE}
	}
	
	@article{mi2018improving,
		title={Improving code readability classification using convolutional neural networks},
		author={Mi, Qing and Keung, Jacky and Xiao, Yan and Mensah, Solomon and Gao, Yujin},
		journal={Information and Software Technology},
		volume={104},
		pages={60--71},
		year={2018},
		publisher={Elsevier}
	}
	
	@book{brooks1987no,
		title={No silver bullet},
		author={Brooks, Frederick and Kugler, H},
		year={1987},
		publisher={April}
	}
	
	@article{loriot2022styler,
		title={Styler: learning formatting conventions to repair Checkstyle violations},
		author={Loriot, Benjamin and Madeiral, Fernanda and Monperrus, Martin},
		journal={Empirical Software Engineering},
		volume={27},
		number={6},
		pages={149},
		year={2022},
		publisher={Springer}
	}
	
	@inproceedings{yasunaga2020graph,
		title={Graph-based, self-supervised program repair from diagnostic feedback},
		author={Yasunaga, Michihiro and Liang, Percy},
		booktitle={International Conference on Machine Learning},
		pages={10799--10808},
		year={2020},
		organization={PMLR}
	}
	
	@inproceedings{xu2019method,
		title={Method name suggestion with hierarchical attention networks},
		author={Xu, Sihan and Zhang, Sen and Wang, Weijing and Cao, Xinya and Guo, Chenkai and Xu, Jing},
		booktitle={Proceedings of the 2019 ACM SIGPLAN workshop on partial evaluation and program manipulation},
		pages={10--21},
		year={2019}
	}
	
	@inproceedings{allamanis2016convolutional,
		title={A convolutional attention network for extreme summarization of source code},
		author={Allamanis, Miltiadis and Peng, Hao and Sutton, Charles},
		booktitle={International conference on machine learning},
		pages={2091--2100},
		year={2016},
		organization={PMLR}
	}
	
	@article{hestness2017deep,
		title={Deep learning scaling is predictable, empirically},
		author={Hestness, Joel and Narang, Sharan and Ardalani, Newsha and Diamos, Gregory and Jun, Heewoo and Kianinejad, Hassan and Patwary, Md Mostofa Ali and Yang, Yang and Zhou, Yanqi},
		journal={arXiv preprint arXiv:1712.00409},
		year={2017}
	}
	
	@inproceedings{liu2019learning,
		title={Learning to spot and refactor inconsistent method names},
		author={Liu, Kui and Kim, Dongsun and Bissyand{\'e}, Tegawend{\'e} F and Kim, Taeyoung and Kim, Kisub and Koyuncu, Anil and Kim, Suntae and Le Traon, Yves},
		booktitle={2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)},
		pages={1--12},
		year={2019},
		organization={IEEE}
	}
	
	@article{deimel1985uses,
		title={The uses of program reading},
		author={Deimel Jr, Lionel E},
		journal={ACM SIGCSE Bulletin},
		volume={17},
		number={2},
		pages={5--14},
		year={1985},
		publisher={ACM New York, NY, USA}
	}
	
	@inproceedings{raymond1991reading,
		title={Reading source code.},
		author={Raymond, Darrell R},
		booktitle={CASCON},
		volume={91},
		pages={3--16},
		year={1991}
	}
	
	@article{rugaber2000use,
		title={The use of domain knowledge in program understanding},
		author={Rugaber, Spencer},
		journal={Annals of Software Engineering},
		volume={9},
		number={1-4},
		pages={143--192},
		year={2000},
		publisher={Springer}
	}
	
	@article{likert1932technique,
		title={A technique for the measurement of attitudes.},
		author={Likert, Rensis},
		journal={Archives of psychology},
		year={1932}
	}
	
	@inproceedings{wyrich2019towards,
		title={Towards an autonomous bot for automatic source code refactoring},
		author={Wyrich, Marvin and Bogner, Justus},
		booktitle={2019 IEEE/ACM 1st international workshop on bots in software engineering (BotSE)},
		pages={24--28},
		year={2019},
		organization={IEEE}
	}
	
	@article{pawlak2016spoon,
		title={Spoon: A library for implementing analyses and transformations of java source code},
		author={Pawlak, Renaud and Monperrus, Martin and Petitprez, Nicolas and Noguera, Carlos and Seinturier, Lionel},
		journal={Software: Practice and Experience},
		volume={46},
		number={9},
		pages={1155--1179},
		year={2016},
		publisher={Wiley Online Library}
	}
	
	@article{someoliayi2022sorald,
		title={Sorald: Automatic Patch Suggestions for SonarQube Static Analysis Violations},
		author={Someoliayi, Khashayar Etemadi and Harrand, Nicolas Yves Maurice and Larsen, Simon and Adzemovic, Haris and Phu, Henry Luong and Verma, Ashutosh and Madeiral, Fernanda and Wikstrom, Douglas and Monperrus, Martin},
		journal={IEEE Transactions on Dependable and Secure Computing},
		year={2022},
		publisher={IEEE}
	}
	
	@inproceedings{allamanis2015suggesting,
		title={Suggesting accurate method and class names},
		author={Allamanis, Miltiadis and Barr, Earl T and Bird, Christian and Sutton, Charles},
		booktitle={Proceedings of the 2015 10th joint meeting on foundations of software engineering},
		pages={38--49},
		year={2015}
	}
	
	@article{alon2019code2vec,
		title={code2vec: Learning distributed representations of code},
		author={Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran},
		journal={Proceedings of the ACM on Programming Languages},
		volume={3},
		number={POPL},
		pages={1--29},
		year={2019},
		publisher={ACM New York, NY, USA}
	}
	
	@article{chicco2020advantages,
		title={The advantages of the Matthews correlation coefficient (MCC) over F1 score and accuracy in binary classification evaluation},
		author={Chicco, Davide and Jurman, Giuseppe},
		journal={BMC genomics},
		volume={21},
		number={1},
		pages={1--13},
		year={2020},
		publisher={BioMed Central}
	}
\end{filecontents}
\addbibresource{\jobname.bib}

\usepackage{hyperref}

\author{Lukas Krodinger}
\title{Expos√© - Advancing Code Readability: Mined \& Modified Code for Dataset Generation}
\degreeprogramme{M.Sc. Informatik}
\matrnumber{89801}
\supervisor{Prof. Dr. Gordon Fraser}
%\external{Prof.~John Doe,~PhD}
\advisor{Lisa Griebl}
\department{Faculty of Computer Science and Mathematics}
\institute{Chair of Software Engineering II}
\location{Passau}


%%%%%%%%%%%%%%%%%%%%%%
% Installed Packages %
%%%%%%%%%%%%%%%%%%%%%%
% For java code embeddings
\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\usepackage{listings}
\lstset{frame=tb,
	language=Java,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	showstringspaces=true,
	numbers=none,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3
}

% Start counting of chapters with 1
\usepackage{chngcntr}
\counterwithout{chapter}{section}
\counterwithin{chapter}{part}
\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thechapter}{\arabic{chapter}.0}

% Unbold subsubsection
%\usepackage{titlesec}
%\titleformat{\subsubsection}{\normalfont\fontfamily{phv}\fontsize{14}{17}\selectfont}{\thesubsubsection}{1em}{}

\begin{document}
	
	\frontmatter
	
	\maketitle
	
	\mainmatter
	
	\section{Motivation} \label{Motivation}
	
	% TODO: Improve text using chat gpt
	% TODO: Include graphic of functionality?
	% TODO: Include data augmentation
	% TODO: Transformer model for generating bad code?
	
	In the realm of software development, the significance of code readability cannot be overstated. Together with understandability, it 	serves as the foundation for efficient collaboration, comprehension, and maintenance of software systems \cite{posnett2011simpler, aggarwal2002integrated}. 
	Maintenance alone will consume over 70\% of the total lifecycle cost of a software product and for maintenance, the most time-consuming act is reading code \cite{buse2009learning, deimel1985uses, rugaber2000use, boehm2001defect}.
	Therefore, it is important to make sure that a high readability of code is ensured. In order to archive this, we need to measure readability and classify code regarding readability.
	
	In the last years, researchers have proposed several metrics and models for assessing code readability with an accuracy of up to 81.8\% \cite{buse2009learning, posnett2011simpler, dorn2012general, daka2015modeling}. In recent years, the newer deep learning based models are able to achieve an accuracy of up to 85.3\% \cite{mi2018improving, mi2022towards}.
	However, these models do not capture what developers think of readability improvements \cite{fakhoury2019improving}. This suggests that there is room for improvement in readability classification of source code.
	
	\section{Background and related work} \label{Background and related work}
	
	\subsection{Readability} \label{Readability}
	In order to be able to improve readability, we first need to capture what readability is. We define readability as a subjective impression of the difficulty of code while trying to understand it \cite{posnett2011simpler, buse2009learning}. In other words, readability of code is a perceived barrier that needs to be overcome before it is possible to work with the code. The more readable code is, the lower the barrier \cite{posnett2011simpler}.
	To give an example for high vs low readability, consider the code of Listing \ref{lst:cassandra-src-java-org-apache-cassandra-utils} and compare it to the code with the same functionality of Listing \ref{lst:cassandra-src-java-org-apache-cassandra-utils-modified}. You will notice that the first piece of code is much more readable than the second one.
	
	Readability is not the same as complexity. Complexity is an ‚Äúessential‚Äù property of software that arises
	from system requirements, while readability is an ‚Äúaccidental‚Äù property that is not determined by the problem statement \cite{buse2009learning, brooks1987no}.
	
	There is another closely related term, namely understandability. Readability is the syntactic aspect of processing code, while understandability is the semantic aspect \cite{posnett2011simpler}.
	For example, a developer can find a piece of code readable but still difficult to understand. Recent research gives evidence that there is no correlation between understandability and readability \cite{scalabrino2017automatically}.	
	
	\begin{listing}[htb]
		\begin{minted}[linenos, frame=lines, framesep=2mm]{java}
			/**
			* Logs the output of the specified process.
			*
			* @param p the process
			* @throws IOException if an I/O problem occurs
			*/
			private static void logProcessOutput(Process p) throws IOException
			{
				try (BufferedReader input = new BufferedReader(new InputStreamReader(p.getInputStream())))
				{
					StrBuilder builder = new StrBuilder();
					String line;
					while ((line = input.readLine()) != null)
					{
						builder.appendln(line);
					}
					logger.info(builder.toString());
				}
			}
		\end{minted}
		\caption{An example for well readable code of the highly rated Cassandra GitHub repository}
		\label{lst:cassandra-src-java-org-apache-cassandra-utils}
	\end{listing}
	
	\begin{listing}[htb]
		\begin{minted}[linenos, frame=lines, framesep=2mm]{java}
			private 
				static 
			void 
			debug( Process 
			v1 
			)       throws IOException
			{
				// Doo debug
				try (BufferedReader   b 
				= new 
				BufferedReader(
				new InputStreamReader(
				v1.getInputStream()
				)
				)
				)
				{
					StrBuilder b2=new StrBuilder();String v2;while (null!=(v2=input.readLine())){b2.appendln(v2);} // Doo stuff
					m.info(  builder.toString()
					);
				}
			}
		\end{minted}
		\caption{The same example as in Listing \ref{lst:cassandra-src-java-org-apache-cassandra-utils} but modified to be badly readable}
		\label{lst:cassandra-src-java-org-apache-cassandra-utils-modified}
	\end{listing}
	
%	\lstinputlisting[language=Java, firstline=8, lastline=26, caption={An example for highly readable code of the highly rated cassandra github repository},label={lst:cassandra-src-java-org-apache-cassandra-utils}]{cassandra-src-java-org-apache-cassandra-utils.java}
%	
%	\lstinputlisting[language=Java, firstline=8, lastline=29, caption={The same example modified to be badly readable},label={lst:cassandra-src-java-org-apache-cassandra-utils-modified}]{cassandra-src-java-org-apache-cassandra-utils-modified.java}
	
	\subsection{Classical calculation approaches} \label{Classical calculation approaches}
	A first estimation for source code readability was defined as the percentage of comment lines over total code lines \cite{aggarwal2002integrated}. In the last years, researchers have proposed several more complex metrics and models for assessing code readability \cite{buse2009learning, posnett2011simpler, dorn2012general, scalabrino2016improving}.
	Those approaches used handcrafted features to calculate whether a piece of code is readable or not. They were able to achieve up to 81.8\% accuracy in classification \cite{scalabrino2016improving}.
	
	\subsection{Deep Learning based approaches} \label{(Deep) Learning based approaches}
	More recent models use Deep Learning approaches in order to generate the features automatically. Those models have proven to be more accurate, achieving an accuracy of up to 85.3\% \cite{mi2018improving, mi2022towards}.
	
	All the mentioned models were trained on the data of Buse, Dorn and Scalabrio which was generated with surveys. They therefore asked developers several questions, including the question, how well readable the proposed source code is \cite{buse2009learning, dorn2012general, scalabrino2016improving}.
	
	\citeauthor{fakhoury2019improving} showed based on readability improving commit analysis that these models do not capture what developers think of readability improvements. They suggest taking other metrics such as incoming method invocations or method name fitting into account \cite{fakhoury2019improving}.
	
	\subsection{Other related work}
	% TODO: Remove names if not relevant
	\citeauthor{loriot2022styler} created a model that is able to fix Checkstyle\footnote{\url{https://checkstyle.org/}} violations using Deep Learning. He therefore inserted formatting violations based on a project specific format checker ruleset into code in a first step. In a second step, he then learned how to undo those injections using a LSTM neural network. His approach is working on abstract token sequences. Note that all the training data is generated in a self-supervised manner \cite{loriot2022styler}. A similar idea has been explored by \citeauthor{yasunaga2020graph} \cite{yasunaga2020graph}. We will use the idea of intentional degradation of code for data generation.
	
	Another concept we will employ is from \citeauthor{allamanis2016convolutional}. He cloned the top open source Java projects on GitHub\footnote{\url{https://github.com/}} for training a Deep Learning model. Those top projects were selected by taking the sum of the z-scores of the number of watchers and forks of each project. As the projects have thousands of forks and stars and are widely used among software developers, they can be assumed to be of high quality \cite{allamanis2016convolutional}.
	
	\section{Planned Work and Contribution} \label{Planned Work and Contribution}
	We will investigate whether it is possible to score a higher accuracy as current models in classifying code readability for java using Deep Learning. Therefore, we will train the model from \citeauthor{mi2022towards} \cite{mi2022towards} with more data. We will consider augmenting the model with a method name classifier and incorporating semantic encoding for tabs and spaces. The training data will be generated in a novel way for classification of readability, inspired by \citeauthor{loriot2022styler} \cite{loriot2022styler}. The method name classifier would be similar to Code2Vec \cite{alon2019code2vec}. The combination of all components would be novel to the best of our knowledge. You can find a visualization of the planned modifications of \citeauthor{mi2022towards}'s model in figure \ref{fig:model_pipeline}. We will focus on generating training data, as the approach will be usable for further research in the field of source code readability.\\
	
	\begin{figure}[t]
		\centering
		\includegraphics[width=\textwidth]{Model_pipeline.png}
		\caption{Overview of the planned approach.}
		\label{fig:model_pipeline}
	\end{figure}
	
	% TODO: Inline this in research questions?
	% \subsection{Data generation} \label{Data generation}
	Deep Learning based models perform better the more training data they get \cite{hestness2017deep}. Therefore, one approach in order to further improve existing models is to gather more training data.
	This requires, as it was done previously, a lot of effort and persons willing to rate code based on their readability. We present another approach for gathering training data.
	
	In a first step, GitHub repositories with known high code quality are downloaded and labeled as highly readable. We therefore select repositories using a similar approach as \citeauthor{allamanis2016convolutional} \cite{allamanis2016convolutional} and then assume that they contain only well readable code.
	In a second step, the code is manipulated so that it is less readable afterwards. This approach is similar to the approach of \citeauthor{loriot2022styler} \cite{loriot2022styler}.
	
	\begin{resq}What is the quality of our new data generation approach?\end{resq} \label{RQ1}
	So far, the data for readability classification was generated manually. Therefore, human annotators ranked code snippets by their readability level based on a five-point Likert scale \cite{likert1932technique} ranging from one (i.e., very unreadable) to five (i.e., very readable) \cite{buse2009learning, dorn2012general, scalabrino2016improving}. Our new data will be generated in an automatic approach, where no manual labeling of code is necessary. We want to compare the quality of this data to the data used for previous models.
	
	\begin{resq}Can certain code be assumed to be well readable?\end{resq} \label{RQ1.1}
	To collect the necessary training data, we assume that the code from the repositories is readable under certain conditions. We want to check whether that assumption holds.
	
	\begin{resq}Can poorly readable code be generated from well readable code?\end{resq} \label{RQ1.2}
	It is not sufficient to have only well readable code for training a classifier. We also need poorly readable code. Therefore, we will try to generate such code from the well readable code. We will investigate whether this is possible in principle, and we will propose an automated approach for archiving this: Readability Decreasing Heuristics.
	
	\begin{resq}Which heuristics are best to generate poorly readable code from well readable code?\end{resq}
	We want to compare the modifications of the proposed heuristics for generating badly readable code to each other. We will investigate whether their results are sufficient for training a readability classifier.
	
	\begin{resq}Can the new data improve existing readability models?\end{resq} \label{RQ2}
	It was shown that Deep Learning models get better the more training data is available \cite{hestness2017deep}. This holds under the assumption that the quality of the data is the same or at least similar. We want to check if the quality of our new data is sufficient for improving the Deep Learning based readability classifier of \citeauthor{mi2022towards} \cite{mi2022towards}.    
	
	\begin{resq}Optional: How can existing Deep Learning approaches be further improved?\end{resq} \label{RQ3}
	In recent years it was shown that Deep Learning models can be further improved by modifying the structure of the architecture or by introducing new components, parts or layers to existing architectures. We suggest two improvements for the model of \citeauthor{mi2022towards} \cite{mi2022towards} namely embedding spaces and tabs as semantic tokens and adding a method name fitting component. We want to investigate if those changes can improve the model.
	
	\begin{resq}Optional: Does the embedding of spaces and tabs in semantic code representations improve readability classification?\end{resq} \label{RQ3.1}
	The state-of-the-art model of \citeauthor{mi2022towards} \cite{mi2022towards} does consider spaces and tabs only in its visual component. We want to investigate if it can improve the quality of a Deep Learning based model if spaces and tabs are encoded as semantic tokens. We also want to investigate if this makes the visual component superfluous.
	
	\begin{resq}Optional: Does the usage of a method name fitting classifier improve readability classification?\end{resq} \label{RQ3.2}
	Correct naming of identifiers is crucial for ensuring readability of software programs. It is of outstanding importance for readability of code that the name of methods fit the method bodies \cite{liu2019learning}. We want to introduce a new component to the model of\citeauthor{mi2022towards} \cite{mi2022towards} that is built similar to Code2Vec \cite{alon2019code2vec}. We want to investigate if the newly introduced component increases the quality of the resulting model.
	
	\backmatter
	
	\printbibliography
	
\end{document}
